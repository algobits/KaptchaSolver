{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saeedghadiri/KaptchaSolver/blob/main/kaptcha_solver.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiiH8UQGTnpo"
      },
      "source": [
        "# Import packages and set random seeds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0UAWkNATlmx",
        "outputId": "a09442eb-1842-4540-8bac-6ca1d14d8f73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version:  2.7.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from PIL import Image\n",
        "from PIL import ImageFilter\n",
        "from PIL.ImageDraw import Draw\n",
        "from PIL.ImageFont import truetype\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "print(\"Tensorflow version: \", tf.__version__)\n",
        "seed = 1234\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBGXUFQ0YD3b"
      },
      "source": [
        "# Set Parameters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Parameters\n"
      ],
      "metadata": {
        "id": "s3v-qqvechbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_FORMAT = 'jpg'\n",
        "DATA_DIR = '/content/data'\n",
        "\n",
        "# Desired image dimensions\n",
        "img_width=200\n",
        "img_height=50 \n",
        "\n",
        "# text font size\n",
        "font_size = 50\n",
        "# text font color in rgb\n",
        "font_color = '0,0,230'\n",
        "\n",
        "# pool of character to sample from\n",
        "char_pool = '0123456789'\n",
        "\n",
        "# Maximum length of any captcha in the data\n",
        "max_length=5\n",
        "\n",
        "# sample_size\n",
        "sample_size = 20000\n",
        "\n",
        "# number of added space before captcha (for some captcha's we need space before chars)\n",
        "add_space = 22"
      ],
      "metadata": {
        "id": "eQ005ifmcwHI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Parameters"
      ],
      "metadata": {
        "id": "bqodXIBecaZZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "I3c-c0G6U0Ib"
      },
      "outputs": [],
      "source": [
        "# test samples size\n",
        "TEST_SPLIT = 0.2\n",
        "# validation samples size\n",
        "VAL_SPLIT = 0.1\n",
        "\n",
        "# Batch size for training and validation\n",
        "batch_size = 16\n",
        "\n",
        "# Factor by which the image is going to be downsampled by the convolutional blocks\n",
        "downsample_factor=4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create DataSet\n",
        "we use kaptcha generator from https://github.com/saeedghadiri/KaptchaGenerator in order to create our dataset"
      ],
      "metadata": {
        "id": "oiqyxXC_dGWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/saeedghadiri/KaptchaGenerator/blob/master/kaptchagenerator.jar?raw=true\n",
        "!mv kaptchagenerator.jar?raw=true kaptchagenerator.jar\n",
        "!rm -r data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkEZ907zdNRU",
        "outputId": "5bf3260f-2c69-423c-e579-709b62a6f4c2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-26 06:48:12--  https://github.com/saeedghadiri/KaptchaGenerator/blob/master/kaptchagenerator.jar?raw=true\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/saeedghadiri/KaptchaGenerator/raw/master/kaptchagenerator.jar [following]\n",
            "--2021-12-26 06:48:13--  https://github.com/saeedghadiri/KaptchaGenerator/raw/master/kaptchagenerator.jar\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/saeedghadiri/KaptchaGenerator/master/kaptchagenerator.jar [following]\n",
            "--2021-12-26 06:48:13--  https://raw.githubusercontent.com/saeedghadiri/KaptchaGenerator/master/kaptchagenerator.jar\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 575200 (562K) [application/octet-stream]\n",
            "Saving to: ‘kaptchagenerator.jar?raw=true’\n",
            "\n",
            "kaptchagenerator.ja 100%[===================>] 561.72K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-12-26 06:48:13 (13.6 MB/s) - ‘kaptchagenerator.jar?raw=true’ saved [575200/575200]\n",
            "\n",
            "rm: cannot remove 'data': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "subprocess.call(['java', '-jar', 'kaptchagenerator.jar', 'data', str(img_width), str(img_height), str(font_size), font_color, char_pool, str(max_length), str(sample_size), str(add_space)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1V64Sh1ndm0y",
        "outputId": "9f8521cc-581c-4a67-c212-8e917c3a1973"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_Nz7WZKVLcr"
      },
      "source": [
        "# Check data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSAVsff6V3CM"
      },
      "source": [
        "Get list of all the images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nyvq1DvwV89r",
        "outputId": "c791bfea-1374-4323-d9c1-6b061fcf8f1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images found:  18099\n"
          ]
        }
      ],
      "source": [
        "images = list(Path(DATA_DIR).glob(\"*.\" + IMG_FORMAT))\n",
        "print(\"Number of images found: \", len(images))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZgkbzCCV_7b"
      },
      "source": [
        "Let's take a look at some samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "Q5r3wc31tvkr",
        "outputId": "8d5836a9-9d46-43dd-bd1d-708606929016"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of image:  (50, 200, 3)\n",
            "Shape of image:  (50, 200, 3)\n",
            "Shape of image:  (50, 200, 3)\n",
            "Shape of image:  (50, 200, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x216 with 4 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "sample_images = images[:4]\n",
        "\n",
        "_,ax = plt.subplots(2,2, figsize=(5,3))\n",
        "for i in range(4):\n",
        "    img = cv2.imread(str(sample_images[i]))\n",
        "    print(\"Shape of image: \", img.shape)\n",
        "    ax[i//2, i%2].imshow(img)\n",
        "    ax[i//2, i%2].axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hqp-hHIDWIwy"
      },
      "source": [
        "Now take a look at characters used in the captcha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "vije-p1-t7MT",
        "outputId": "17b3a2b8-6450-4cab-8da9-17061b5ddb2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unqiue charcaters in the whole dataset:  10\n",
            "Maximum length of any captcha:  5\n",
            "Characters present:  ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
            "Total number of samples in the dataset:  18099\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0384c7ed-80b2-47ae-8a20-3ee009bf6650\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>img_path</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/data/99164.jpg</td>\n",
              "      <td>99164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/data/34404.jpg</td>\n",
              "      <td>34404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/data/62135.jpg</td>\n",
              "      <td>62135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/data/69021.jpg</td>\n",
              "      <td>69021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/data/94619.jpg</td>\n",
              "      <td>94619</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0384c7ed-80b2-47ae-8a20-3ee009bf6650')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0384c7ed-80b2-47ae-8a20-3ee009bf6650 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0384c7ed-80b2-47ae-8a20-3ee009bf6650');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                  img_path  label\n",
              "0  /content/data/99164.jpg  99164\n",
              "1  /content/data/34404.jpg  34404\n",
              "2  /content/data/62135.jpg  62135\n",
              "3  /content/data/69021.jpg  69021\n",
              "4  /content/data/94619.jpg  94619"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Store all the characters in a set\n",
        "characters = set()\n",
        "\n",
        "# A list to store the length of each captcha\n",
        "captcha_length = []\n",
        "\n",
        "# Store image-label info\n",
        "dataset = []\n",
        "\n",
        "# Iterate over the dataset and store the\n",
        "# information needed\n",
        "for img_path in images:\n",
        "    # 1. Get the label associated with each image\n",
        "    label = img_path.name.split(\".\" + IMG_FORMAT)[0]\n",
        "    # 2. Store the length of this cpatcha\n",
        "    captcha_length.append(len(label))\n",
        "    # 3. Store the image-label pair info\n",
        "    dataset.append((str(img_path), label))\n",
        "    \n",
        "    # 4. Store the characters present\n",
        "    for ch in label:\n",
        "        characters.add(ch)\n",
        "\n",
        "# Sort the characters        \n",
        "characters = sorted(characters)\n",
        "\n",
        "# Convert the dataset info into a dataframe\n",
        "dataset = pd.DataFrame(dataset, columns=[\"img_path\", \"label\"], index=None)\n",
        "\n",
        "# Shuffle the dataset\n",
        "dataset = dataset.sample(frac=1.).reset_index(drop=True)\n",
        "\n",
        "\n",
        "print(\"Number of unqiue charcaters in the whole dataset: \", len(characters))\n",
        "print(\"Maximum length of any captcha: \", max(Counter(captcha_length).keys()))\n",
        "print(\"Characters present: \", characters)\n",
        "print(\"Total number of samples in the dataset: \", len(dataset))\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fyvn7GjVf45"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfCbDlVnt83T",
        "outputId": "a268c2f5-8176-4a8a-b843-d12de2ffa64c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples:  13031\n",
            "Number of validation samples:  1448\n",
            "Number of test samples:  3620\n",
            "Number of training images:  (13031, 50, 200)\n",
            "Number of training labels:  (13031,)\n",
            "Number of validation images:  (1448, 50, 200)\n",
            "Number of validation labels:  (1448,)\n",
            "Number of test images:  (3620, 50, 200)\n",
            "Number of test labels:  (3620,)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Split the dataset into training and validation and test sets\n",
        "train_dataset, test_data = train_test_split(dataset, test_size=TEST_SPLIT, random_state=seed)\n",
        "training_data, validation_data = train_test_split(train_dataset, test_size=VAL_SPLIT, random_state=seed)\n",
        "\n",
        "training_data = training_data.reset_index(drop=True)\n",
        "validation_data = validation_data.reset_index(drop=True)\n",
        "test_data = test_data.reset_index(drop=True)\n",
        "\n",
        "print(\"Number of training samples: \", len(training_data))\n",
        "print(\"Number of validation samples: \", len(validation_data))\n",
        "print(\"Number of test samples: \", len(test_data))\n",
        "\n",
        "\n",
        "# Map text to numeric labels \n",
        "char_to_labels = {char:idx for idx, char in enumerate(characters)}\n",
        "\n",
        "# Map numeric labels to text\n",
        "labels_to_char = {val:key for key, val in char_to_labels.items()}\n",
        "\n",
        "\n",
        "\n",
        "# Sanity check for corrupted images\n",
        "def is_valid_captcha(captcha):\n",
        "    for ch in captcha:\n",
        "        if not ch in characters:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "\n",
        "\n",
        "# Store arrays in memory as it's not a muvh big dataset\n",
        "def generate_arrays(df, resize=True, img_height=50, img_width=200):\n",
        "    \"\"\"Generates image array and labels array from a dataframe.\n",
        "    \n",
        "    Args:\n",
        "        df: dataframe from which we want to read the data\n",
        "        resize (bool)    : whether to resize images or not\n",
        "        img_weidth (int): width of the resized images\n",
        "        img_height (int): height of the resized images\n",
        "        \n",
        "    Returns:\n",
        "        images (ndarray): grayscale images\n",
        "        labels (ndarray): corresponding encoded labels\n",
        "    \"\"\"\n",
        "\n",
        "    lower = np.array([150, 0, 0])\n",
        "    upper = np.array([255, 150, 150])\n",
        "    \n",
        "    num_items = len(df)\n",
        "    images = np.zeros((num_items, img_height, img_width), dtype=np.float32)\n",
        "    labels = [0]*num_items\n",
        "    \n",
        "    for i in range(num_items):\n",
        "        img = cv2.imread(df[\"img_path\"][i])\n",
        "\n",
        "        img = cv2.inRange(img, lower, upper)\n",
        "        # img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        \n",
        "        if resize: \n",
        "            img = cv2.resize(img, (img_width, img_height))\n",
        "        \n",
        "        img = (img/255.).astype(np.float32)\n",
        "        label = df[\"label\"][i]\n",
        "        \n",
        "        # Add only if it is a valid captcha\n",
        "        if is_valid_captcha(label):\n",
        "            images[i, :, :] = img\n",
        "            labels[i] = label\n",
        "    \n",
        "    return images, np.array(labels)\n",
        "\n",
        "\n",
        "\n",
        "# Build training data\n",
        "training_data, training_labels = generate_arrays(df=training_data)\n",
        "print(\"Number of training images: \", training_data.shape)\n",
        "print(\"Number of training labels: \", training_labels.shape)\n",
        "\n",
        "\n",
        "# Build validation data\n",
        "validation_data, validation_labels = generate_arrays(df=validation_data)\n",
        "print(\"Number of validation images: \", validation_data.shape)\n",
        "print(\"Number of validation labels: \", validation_labels.shape)\n",
        "\n",
        "\n",
        "# Build validation data\n",
        "test_data, test_labels = generate_arrays(df=test_data)\n",
        "print(\"Number of test images: \", test_data.shape)\n",
        "print(\"Number of test labels: \", test_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "P4oKT-jvt-gL"
      },
      "outputs": [],
      "source": [
        "class DataGenerator(keras.utils.Sequence):\n",
        "    \"\"\"Generates batches from a given dataset.\n",
        "    \n",
        "    Args:\n",
        "        data: training or validation data\n",
        "        labels: corresponding labels\n",
        "        char_map: dictionary mapping char to labels\n",
        "        batch_size: size of a single batch\n",
        "        img_width: width of the resized\n",
        "        img_height: height of the resized\n",
        "        downsample_factor: by what factor did the CNN downsample the images\n",
        "        max_length: maximum length of any captcha\n",
        "        shuffle: whether to shuffle data or not after each epoch\n",
        "    Returns:\n",
        "        batch_inputs: a dictionary containing batch inputs \n",
        "        batch_labels: a batch of corresponding labels \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self,\n",
        "                 data,\n",
        "                 labels,\n",
        "                 char_map,\n",
        "                 batch_size=16,\n",
        "                 img_width=200,\n",
        "                 img_height=50,\n",
        "                 downsample_factor=4,\n",
        "                 max_length=5,\n",
        "                 shuffle=True\n",
        "                ):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.char_map = char_map\n",
        "        self.batch_size = batch_size\n",
        "        self.img_width = img_width\n",
        "        self.img_height = img_height\n",
        "        self.downsample_factor = downsample_factor\n",
        "        self.max_length = max_length\n",
        "        self.shuffle = shuffle\n",
        "        self.indices = np.arange(len(data))    \n",
        "        self.on_epoch_end()\n",
        "        \n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.data) / self.batch_size))\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # 1. Get the next batch indices\n",
        "        curr_batch_idx = self.indices[idx*self.batch_size:(idx+1)*self.batch_size]\n",
        "        \n",
        "        # 2. This isn't necessary but it can help us save some memory\n",
        "        # as not all batches the last batch may not have elements\n",
        "        # equal to the batch_size \n",
        "        batch_len = len(curr_batch_idx)\n",
        "        \n",
        "        # 3. Instantiate batch arrays\n",
        "        batch_images = np.ones((batch_len, self.img_width, self.img_height, 1),\n",
        "                               dtype=np.float32)\n",
        "        batch_labels = np.ones((batch_len, self.max_length), dtype=np.float32)\n",
        "        input_length = np.ones((batch_len, 1), dtype=np.int64) * \\\n",
        "                                (self.img_width // self.downsample_factor - 2)\n",
        "        label_length = np.zeros((batch_len, 1), dtype=np.int64)\n",
        "        \n",
        "        \n",
        "        for j, idx in enumerate(curr_batch_idx):\n",
        "            # 1. Get the image and transpose it\n",
        "            img = self.data[idx].T\n",
        "            # 2. Add extra dimenison\n",
        "            img = np.expand_dims(img, axis=-1)\n",
        "            # 3. Get the correpsonding label\n",
        "            text = self.labels[idx]\n",
        "            # 4. Include the pair only if the captcha is valid\n",
        "            if is_valid_captcha(text):\n",
        "                label = [self.char_map[ch] for ch in text]\n",
        "                batch_images[j] = img\n",
        "                batch_labels[j] = label\n",
        "                label_length[j] = len(text)\n",
        "        \n",
        "        batch_inputs = {\n",
        "                'input_data': batch_images,\n",
        "                'input_label': batch_labels,\n",
        "                'input_length': input_length,\n",
        "                'label_length': label_length,\n",
        "                }\n",
        "        return batch_inputs, np.zeros(batch_len).astype(np.float32)\n",
        "        \n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "oUKfFR6IuAAb"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Get a generator object for the training data\n",
        "train_data_generator = DataGenerator(data=training_data,\n",
        "                                     labels=training_labels,\n",
        "                                     char_map=char_to_labels,\n",
        "                                     batch_size=batch_size,\n",
        "                                     img_width=img_width,\n",
        "                                     img_height=img_height,\n",
        "                                     downsample_factor=downsample_factor,\n",
        "                                     max_length=max_length,\n",
        "                                     shuffle=True\n",
        "                                    )\n",
        "\n",
        "# Get a generator object for the validation data \n",
        "valid_data_generator = DataGenerator(data=validation_data,\n",
        "                                     labels=validation_labels,\n",
        "                                     char_map=char_to_labels,\n",
        "                                     batch_size=batch_size,\n",
        "                                     img_width=img_width,\n",
        "                                     img_height=img_height,\n",
        "                                     downsample_factor=downsample_factor,\n",
        "                                     max_length=max_length,\n",
        "                                     shuffle=False\n",
        "                                    )\n",
        "\n",
        "# Get a generator object for the validation data \n",
        "test_data_generator = DataGenerator(data=test_data,\n",
        "                                     labels=test_labels,\n",
        "                                     char_map=char_to_labels,\n",
        "                                     batch_size=batch_size,\n",
        "                                     img_width=img_width,\n",
        "                                     img_height=img_height,\n",
        "                                     downsample_factor=downsample_factor,\n",
        "                                     max_length=max_length,\n",
        "                                     shuffle=False\n",
        "                                    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0ZDUQoDZbKL"
      },
      "source": [
        "# Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btMzMHh-uBZj",
        "outputId": "a7df0aa8-0a16-4f09-c472-12bc760c90cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"ocr_model_v1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_data (InputLayer)        [(None, 200, 50, 1)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " Conv1 (Conv2D)                 (None, 200, 50, 32)  320         ['input_data[0][0]']             \n",
            "                                                                                                  \n",
            " pool1 (MaxPooling2D)           (None, 100, 25, 32)  0           ['Conv1[0][0]']                  \n",
            "                                                                                                  \n",
            " Conv2 (Conv2D)                 (None, 100, 25, 64)  18496       ['pool1[0][0]']                  \n",
            "                                                                                                  \n",
            " pool2 (MaxPooling2D)           (None, 50, 12, 64)   0           ['Conv2[0][0]']                  \n",
            "                                                                                                  \n",
            " reshape (Reshape)              (None, 50, 768)      0           ['pool2[0][0]']                  \n",
            "                                                                                                  \n",
            " dense1 (Dense)                 (None, 50, 64)       49216       ['reshape[0][0]']                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 50, 64)       0           ['dense1[0][0]']                 \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  (None, 50, 256)      197632      ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " bidirectional_1 (Bidirectional  (None, 50, 128)     164352      ['bidirectional[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " input_label (InputLayer)       [(None, 5)]          0           []                               \n",
            "                                                                                                  \n",
            " dense2 (Dense)                 (None, 50, 11)       1419        ['bidirectional_1[0][0]']        \n",
            "                                                                                                  \n",
            " input_length (InputLayer)      [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " label_length (InputLayer)      [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " ctc_loss (CTCLayer)            (None, 1)            0           ['input_label[0][0]',            \n",
            "                                                                  'dense2[0][0]',                 \n",
            "                                                                  'input_length[0][0]',           \n",
            "                                                                  'label_length[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 431,435\n",
            "Trainable params: 431,435\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "class CTCLayer(layers.Layer):\n",
        "    def __init__(self, name=None):\n",
        "        super().__init__(name=name)\n",
        "        self.loss_fn = keras.backend.ctc_batch_cost\n",
        "\n",
        "    def call(self, y_true, y_pred, input_length, label_length):\n",
        "        # Compute the training-time loss value and add it\n",
        "        # to the layer using `self.add_loss()`.\n",
        "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
        "        self.add_loss(loss)\n",
        "        \n",
        "        # On test time, just return the computed loss\n",
        "        return loss\n",
        "\n",
        "\n",
        "\n",
        "def build_model():\n",
        "    # Inputs to the model\n",
        "    input_img = layers.Input(shape=(img_width, img_height, 1),\n",
        "                            name='input_data',\n",
        "                            dtype='float32')\n",
        "    labels = layers.Input(name='input_label', shape=[max_length], dtype='float32')\n",
        "    input_length = layers.Input(name='input_length', shape=[1], dtype='int64')\n",
        "    label_length = layers.Input(name='label_length', shape=[1], dtype='int64')\n",
        "    \n",
        "    # First conv block\n",
        "    x = layers.Conv2D(32,\n",
        "               (3,3),\n",
        "               activation='relu',\n",
        "               kernel_initializer='he_normal',\n",
        "               padding='same',\n",
        "               name='Conv1')(input_img)\n",
        "    x = layers.MaxPooling2D((2,2), name='pool1')(x)\n",
        "    \n",
        "    # Second conv block\n",
        "    x = layers.Conv2D(64,\n",
        "               (3,3),\n",
        "               activation='relu',\n",
        "               kernel_initializer='he_normal',\n",
        "               padding='same',\n",
        "               name='Conv2')(x)\n",
        "    x = layers.MaxPooling2D((2,2), name='pool2')(x)\n",
        "    \n",
        "    # We have used two max pool with pool size and strides of 2.\n",
        "    # Hence, downsampled feature maps are 4x smaller. The number of\n",
        "    # filters in the last layer is 64. Reshape accordingly before\n",
        "    # passing it to RNNs\n",
        "    new_shape = ((img_width // 4), (img_height // 4)*64)\n",
        "    x = layers.Reshape(target_shape=new_shape, name='reshape')(x)\n",
        "    x = layers.Dense(64, activation='relu', name='dense1')(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    \n",
        "    # RNNs\n",
        "    x = layers.Bidirectional(layers.LSTM(128,\n",
        "                                         return_sequences=True,\n",
        "                                         dropout=0.2))(x)\n",
        "    x = layers.Bidirectional(layers.LSTM(64,\n",
        "                                         return_sequences=True,\n",
        "                                         dropout=0.25))(x)\n",
        "    \n",
        "    # Predictions\n",
        "    x = layers.Dense(len(characters)+1,\n",
        "              activation='softmax', \n",
        "              name='dense2',\n",
        "              kernel_initializer='he_normal')(x)\n",
        "    \n",
        "    # Calculate CTC\n",
        "    output = CTCLayer(name='ctc_loss')(labels, x, input_length, label_length)\n",
        "    \n",
        "    # Define the model\n",
        "    model = keras.models.Model(inputs=[input_img,\n",
        "                                       labels,\n",
        "                                       input_length,\n",
        "                                       label_length],\n",
        "                                outputs=output,\n",
        "                                name='ocr_model_v1')\n",
        "    \n",
        "    # Optimizer\n",
        "    sgd = keras.optimizers.SGD(learning_rate=0.002,\n",
        "                               decay=1e-6,\n",
        "                               momentum=0.9,\n",
        "                               nesterov=True,\n",
        "                               clipnorm=5)\n",
        "    \n",
        "    # Compile the model and return \n",
        "    model.compile(optimizer=sgd)\n",
        "    return model\n",
        "\n",
        "model = build_model()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYpKIAxVZkh3"
      },
      "source": [
        "# Fit the model to dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3qlVeWCuC4L",
        "outputId": "feeae396-5364-49d5-e077-b063be537744"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "815/815 [==============================] - 98s 97ms/step - loss: 9.8940 - val_loss: 3.8199\n",
            "Epoch 2/200\n",
            "815/815 [==============================] - 75s 92ms/step - loss: 1.6058 - val_loss: 0.2796\n",
            "Epoch 3/200\n",
            "815/815 [==============================] - 76s 93ms/step - loss: 0.3935 - val_loss: 0.0957\n",
            "Epoch 4/200\n",
            "815/815 [==============================] - 76s 93ms/step - loss: 0.2151 - val_loss: 0.0480\n",
            "Epoch 5/200\n",
            "815/815 [==============================] - 76s 93ms/step - loss: 0.1390 - val_loss: 0.0363\n",
            "Epoch 6/200\n",
            "815/815 [==============================] - 76s 93ms/step - loss: 0.1056 - val_loss: 0.0253\n",
            "Epoch 7/200\n",
            "815/815 [==============================] - 78s 95ms/step - loss: 0.0656 - val_loss: 0.0250\n",
            "Epoch 8/200\n",
            "815/815 [==============================] - 76s 93ms/step - loss: 0.0646 - val_loss: 0.0309\n",
            "Epoch 9/200\n",
            "815/815 [==============================] - 76s 93ms/step - loss: 0.0473 - val_loss: 0.0235\n",
            "Epoch 10/200\n",
            "815/815 [==============================] - 76s 93ms/step - loss: 0.0399 - val_loss: 0.0190\n",
            "Epoch 11/200\n",
            "815/815 [==============================] - 75s 92ms/step - loss: 0.0349 - val_loss: 0.0140\n",
            "Epoch 12/200\n",
            "815/815 [==============================] - 75s 92ms/step - loss: 0.0237 - val_loss: 0.0202\n",
            "Epoch 13/200\n",
            "815/815 [==============================] - 76s 93ms/step - loss: 0.0183 - val_loss: 0.0104\n",
            "Epoch 14/200\n",
            "815/815 [==============================] - 76s 93ms/step - loss: 0.0155 - val_loss: 0.0102\n",
            "Epoch 15/200\n",
            "815/815 [==============================] - 76s 93ms/step - loss: 0.0162 - val_loss: 0.0090\n",
            "Epoch 16/200\n",
            "815/815 [==============================] - 76s 93ms/step - loss: 0.0167 - val_loss: 0.0075\n",
            "Epoch 17/200\n",
            "815/815 [==============================] - 75s 92ms/step - loss: 0.0162 - val_loss: 0.0082\n",
            "Epoch 18/200\n",
            "815/815 [==============================] - 75s 92ms/step - loss: 0.0105 - val_loss: 0.0165\n",
            "Epoch 19/200\n",
            "815/815 [==============================] - 75s 92ms/step - loss: 0.0086 - val_loss: 0.0120\n",
            "Epoch 20/200\n",
            "815/815 [==============================] - 76s 93ms/step - loss: 0.0068 - val_loss: 0.0085\n",
            "Epoch 21/200\n",
            "815/815 [==============================] - 76s 94ms/step - loss: 0.0099 - val_loss: 0.0032\n",
            "Epoch 22/200\n",
            "815/815 [==============================] - 76s 94ms/step - loss: 0.0102 - val_loss: 0.0026\n",
            "Epoch 23/200\n",
            "815/815 [==============================] - 75s 92ms/step - loss: 0.0043 - val_loss: 0.0123\n",
            "Epoch 24/200\n",
            "815/815 [==============================] - 75s 92ms/step - loss: 0.0074 - val_loss: 0.0244\n",
            "Epoch 25/200\n",
            "815/815 [==============================] - 75s 92ms/step - loss: 0.0059 - val_loss: 0.0090\n",
            "Epoch 26/200\n",
            "815/815 [==============================] - 75s 92ms/step - loss: 0.0066 - val_loss: 0.0172\n",
            "Epoch 27/200\n",
            "815/815 [==============================] - 75s 92ms/step - loss: 0.0060 - val_loss: 0.0062\n"
          ]
        }
      ],
      "source": [
        "# Add early stopping\n",
        "es = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                   patience=5,\n",
        "                                   restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_data_generator,\n",
        "                    validation_data=valid_data_generator,\n",
        "                    epochs=200,\n",
        "                    callbacks=[es])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMYyTQWnZvE-"
      },
      "source": [
        "# Save the model to use it later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUbR8VVyuEkG",
        "outputId": "b2e3f1a1-0184-4faf-bd2d-bc5f34fdd2b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_data (InputLayer)     [(None, 200, 50, 1)]      0         \n",
            "                                                                 \n",
            " Conv1 (Conv2D)              (None, 200, 50, 32)       320       \n",
            "                                                                 \n",
            " pool1 (MaxPooling2D)        (None, 100, 25, 32)       0         \n",
            "                                                                 \n",
            " Conv2 (Conv2D)              (None, 100, 25, 64)       18496     \n",
            "                                                                 \n",
            " pool2 (MaxPooling2D)        (None, 50, 12, 64)        0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 50, 768)           0         \n",
            "                                                                 \n",
            " dense1 (Dense)              (None, 50, 64)            49216     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 50, 64)            0         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 50, 256)          197632    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 50, 128)          164352    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense2 (Dense)              (None, 50, 11)            1419      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 431,435\n",
            "Trainable params: 431,435\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/model.pkl/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/model.pkl/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f0cd0353710> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f0cde71ac90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f0cd0248a50> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f0cd01f9d10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "prediction_model = keras.models.Model(model.get_layer(name='input_data').input,\n",
        "                                        model.get_layer(name='dense2').output)\n",
        "prediction_model.summary()\n",
        "prediction_model.save('/content/model.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "z3u24RLhuHVm"
      },
      "outputs": [],
      "source": [
        "# A utility to decode the output of the network\n",
        "def decode_batch_predictions(pred):\n",
        "    pred = pred[:, :-2]\n",
        "    input_len = np.ones(pred.shape[0])*pred.shape[1]\n",
        "    \n",
        "    # Use greedy search. For complex tasks, you can use beam search\n",
        "    results = keras.backend.ctc_decode(pred, \n",
        "                                        input_length=input_len,\n",
        "                                        greedy=True)[0][0]\n",
        "    \n",
        "    # Iterate over the results and get back the text\n",
        "    output_text = []\n",
        "    for res in results.numpy():\n",
        "        outstr = ''\n",
        "        for c in res:\n",
        "            if c < len(characters) and c >=0:\n",
        "                outstr += labels_to_char[c]\n",
        "        output_text.append(outstr)\n",
        "    \n",
        "    # return final text results\n",
        "    return output_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SQtsa54dxUM"
      },
      "source": [
        "Let's check results on some test samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aR519zKUuJZu",
        "outputId": "ce7d7799-7ee3-494d-a8ce-05df0f6748cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(16, 50, 11)\n",
            "Ground truth: 98919 \t Predicted: 98919\n",
            "Ground truth: 79895 \t Predicted: 79895\n",
            "Ground truth: 75142 \t Predicted: 75142\n",
            "Ground truth: 71017 \t Predicted: 71017\n",
            "Ground truth: 95265 \t Predicted: 95265\n",
            "Ground truth: 13022 \t Predicted: 13022\n",
            "Ground truth: 53102 \t Predicted: 53102\n",
            "Ground truth: 33115 \t Predicted: 33115\n",
            "Ground truth: 57232 \t Predicted: 57232\n",
            "Ground truth: 54450 \t Predicted: 54450\n",
            "Ground truth: 66797 \t Predicted: 66797\n",
            "Ground truth: 92795 \t Predicted: 92795\n",
            "Ground truth: 87246 \t Predicted: 87246\n",
            "Ground truth: 06301 \t Predicted: 06301\n",
            "Ground truth: 80829 \t Predicted: 80829\n",
            "Ground truth: 89350 \t Predicted: 89350\n"
          ]
        }
      ],
      "source": [
        "for p, (inp_value, _) in enumerate(test_data_generator):\n",
        "    bs = inp_value['input_data'].shape[0]\n",
        "    X_data = inp_value['input_data']\n",
        "    labels = inp_value['input_label']\n",
        "    print(type(X_data))\n",
        "    preds = prediction_model.predict(X_data)\n",
        "    print(preds.shape)\n",
        "    pred_texts = decode_batch_predictions(preds)\n",
        "    \n",
        "    \n",
        "    orig_texts = []\n",
        "    for label in labels:\n",
        "        text = ''.join([labels_to_char[int(x)] for x in label])\n",
        "        orig_texts.append(text)\n",
        "        \n",
        "    for i in range(bs):\n",
        "        print(f'Ground truth: {orig_texts[i]} \\t Predicted: {pred_texts[i]}')\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PWy9j36dr39"
      },
      "source": [
        "Find accuracy on test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLAjYjwC-4Nm",
        "outputId": "f367056d-49a9-4bff-9e15-71302f8d0d7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:559: UserWarning: Input dict contained keys ['input_label', 'input_length', 'label_length'] which did not match any model input. They will be ignored by the model.\n",
            "  inputs = self._flatten_to_reference_inputs(inputs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_acc: 0.9994475138121547\n"
          ]
        }
      ],
      "source": [
        "preds = prediction_model.predict(test_data_generator)\n",
        "pred_texts = decode_batch_predictions(preds)\n",
        "test_acc = np.sum(np.asarray(pred_texts) == test_data_generator.labels)/len(pred_texts)\n",
        "print('test_acc: {}'.format(test_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fq3SAij_uKFG"
      },
      "source": [
        "# Use the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ctRRM_08uNMn"
      },
      "outputs": [],
      "source": [
        "MODEL_DIR = '/content/drive/MyDrive/colab_data/model.pkl'\n",
        "\n",
        "characters = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "labels_to_char = {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9'}\n",
        "lower = np.array([150, 0, 0])\n",
        "upper = np.array([255, 150, 150])\n",
        "\n",
        "class CaptchaDeepSolver:\n",
        "    def __init__(self, model_path, img_width=200, img_height=50):\n",
        "        self.model = tf.keras.models.load_model(model_path, compile=False)\n",
        "\n",
        "        self.img_width = img_width\n",
        "        self.img_height = img_height\n",
        "\n",
        "    def solve(self, image, resize=True):\n",
        "\n",
        "        img = cv2.inRange(image, lower, upper)\n",
        "        # img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        if resize:\n",
        "            img = cv2.resize(img, (self.img_width, self.img_height))\n",
        "\n",
        "        img = (img / 255.).astype(np.float32)\n",
        "        img = img.T\n",
        "\n",
        "        img = np.expand_dims(img, axis=-1)\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "        preds = self.model.predict(img)\n",
        "        pred_texts = self.decode_batch_predictions(preds)\n",
        "        return pred_texts\n",
        "\n",
        "    # A utility to decode the output of the network\n",
        "    @staticmethod\n",
        "    def decode_batch_predictions(prediction):\n",
        "        pred = prediction[:, :-2]\n",
        "        input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
        "\n",
        "        # Use greedy search. For complex tasks, you can use beam search\n",
        "        results = keras.backend.ctc_decode(pred,\n",
        "                                           input_length=input_len,\n",
        "                                           greedy=True)[0][0]\n",
        "\n",
        "        # Iterate over the results and get back the text\n",
        "        output_text = []\n",
        "        for res in results.numpy():\n",
        "            outstr = ''\n",
        "            for c in res:\n",
        "                if c < len(characters) and c >= 0:\n",
        "                    outstr += labels_to_char[c]\n",
        "            output_text.append(outstr)\n",
        "\n",
        "        # return final text results\n",
        "        return output_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aD5yUV9buPsG",
        "outputId": "dd9a0834-d586-4e77-86e8-92b9ed7d8d53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "true: 99164 predicted: ['99164']\n",
            "true: 34404 predicted: ['34404']\n",
            "true: 62135 predicted: ['62135']\n",
            "true: 69021 predicted: ['69021']\n",
            "true: 94619 predicted: ['94619']\n",
            "true: 50217 predicted: ['50217']\n",
            "true: 25750 predicted: ['25750']\n",
            "true: 27488 predicted: ['27488']\n",
            "true: 20272 predicted: ['20272']\n",
            "true: 73751 predicted: ['73751']\n",
            "true: 71752 predicted: ['71752']\n",
            "true: 13299 predicted: ['13299']\n",
            "true: 25717 predicted: ['25717']\n",
            "true: 98472 predicted: ['98472']\n",
            "true: 42006 predicted: ['42006']\n",
            "true: 04765 predicted: ['04765']\n",
            "true: 05012 predicted: ['05012']\n",
            "true: 60374 predicted: ['60374']\n",
            "true: 95388 predicted: ['95388']\n",
            "true: 69789 predicted: ['69789']\n",
            "true: 30734 predicted: ['30734']\n",
            "true: 10974 predicted: ['10974']\n",
            "true: 90016 predicted: ['90016']\n",
            "true: 98972 predicted: ['98972']\n",
            "true: 07057 predicted: ['07057']\n",
            "true: 45881 predicted: ['45881']\n",
            "true: 98936 predicted: ['98936']\n",
            "true: 99443 predicted: ['99443']\n",
            "true: 68817 predicted: ['68817']\n",
            "true: 72262 predicted: ['72262']\n",
            "true: 93099 predicted: ['93099']\n",
            "true: 18635 predicted: ['18635']\n",
            "true: 83722 predicted: ['83722']\n",
            "true: 36581 predicted: ['36581']\n",
            "true: 91262 predicted: ['91262']\n",
            "true: 97604 predicted: ['97604']\n",
            "true: 94057 predicted: ['94057']\n",
            "true: 80117 predicted: ['80117']\n",
            "true: 77320 predicted: ['77320']\n",
            "true: 62312 predicted: ['62312']\n",
            "true: 57963 predicted: ['57963']\n",
            "true: 44792 predicted: ['44792']\n",
            "true: 19393 predicted: ['19393']\n",
            "true: 02638 predicted: ['02638']\n",
            "true: 57973 predicted: ['57973']\n",
            "true: 79520 predicted: ['79520']\n",
            "true: 49094 predicted: ['49094']\n",
            "true: 64147 predicted: ['64147']\n",
            "true: 76229 predicted: ['76229']\n",
            "true: 27525 predicted: ['27525']\n",
            "true: 38491 predicted: ['38491']\n",
            "true: 64548 predicted: ['64548']\n",
            "true: 74208 predicted: ['74208']\n",
            "true: 71562 predicted: ['71562']\n",
            "true: 67670 predicted: ['67670']\n",
            "true: 22768 predicted: ['22768']\n",
            "true: 73248 predicted: ['73248']\n",
            "true: 72040 predicted: ['72040']\n",
            "true: 13342 predicted: ['13342']\n",
            "true: 99446 predicted: ['99446']\n",
            "true: 43584 predicted: ['43584']\n",
            "true: 74353 predicted: ['74353']\n",
            "true: 13350 predicted: ['13350']\n",
            "true: 14434 predicted: ['14434']\n",
            "true: 17785 predicted: ['17785']\n",
            "true: 70576 predicted: ['70576']\n",
            "true: 29634 predicted: ['29634']\n",
            "true: 98786 predicted: ['98786']\n",
            "true: 91440 predicted: ['91440']\n",
            "true: 62482 predicted: ['62482']\n",
            "true: 87433 predicted: ['87433']\n",
            "true: 38712 predicted: ['38712']\n",
            "true: 34626 predicted: ['34626']\n",
            "true: 34950 predicted: ['34950']\n",
            "true: 64996 predicted: ['64996']\n",
            "true: 24273 predicted: ['24273']\n",
            "true: 92008 predicted: ['92008']\n",
            "true: 17969 predicted: ['17969']\n",
            "true: 99974 predicted: ['99974']\n",
            "true: 31486 predicted: ['31486']\n",
            "true: 77806 predicted: ['77806']\n",
            "true: 58544 predicted: ['58544']\n",
            "true: 19041 predicted: ['19041']\n",
            "true: 75410 predicted: ['75410']\n",
            "true: 42410 predicted: ['42410']\n",
            "true: 97342 predicted: ['97342']\n",
            "true: 76685 predicted: ['76685']\n",
            "true: 96676 predicted: ['96676']\n",
            "true: 90502 predicted: ['90502']\n",
            "true: 47988 predicted: ['47988']\n",
            "true: 68006 predicted: ['68006']\n",
            "true: 28001 predicted: ['28001']\n",
            "true: 01384 predicted: ['01384']\n",
            "true: 50058 predicted: ['50058']\n",
            "true: 15996 predicted: ['15996']\n",
            "true: 12763 predicted: ['12763']\n",
            "true: 79562 predicted: ['79562']\n",
            "true: 90817 predicted: ['90817']\n",
            "true: 44532 predicted: ['44532']\n",
            "true: 25830 predicted: ['25830']\n"
          ]
        }
      ],
      "source": [
        "# Load the model\n",
        "model = CaptchaDeepSolver('/content/model.pkl')\n",
        "\n",
        "for index, row in dataset[:100].iterrows():\n",
        "  # Load the image\n",
        "  img = cv2.imread(row['img_path'])\n",
        "\n",
        "  # Predict the text\n",
        "  pred_texts = model.solve(img)\n",
        "\n",
        "  # Print the results\n",
        "  print('true: {} predicted: {}'.format(row['label'], pred_texts))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "kaptcha solver.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP33oxk73fYeeUh0nkYoyyA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}